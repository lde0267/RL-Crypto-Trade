import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pandas as pd

class TradingEnv(gym.Env):
    """
    [ìˆ˜ì •ë¨]
    - ì •ê·œí™” í†µê³„(means/stds)ë¥¼ ë‚´ë¶€ì—ì„œ ê³„ì‚°í•˜ì§€ ì•Šê³ ,
    - ì™¸ë¶€ì—ì„œ íŒŒë¼ë¯¸í„°ë¡œ ì£¼ì…ë°›ì•„ ë°ì´í„° ìœ ì¶œ(Lookahead Bias)ì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    metadata = {"render.modes": ["human"]}

    # âœ… [ìˆ˜ì •] __init__ ì‹œê·¸ë‹ˆì²˜ ë³€ê²½: obs_meansì™€ obs_stdsë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ìŒ
    def __init__(self, df: pd.DataFrame, 
                 obs_means: pd.Series, 
                 obs_stds: pd.Series,
                 window_size: int = 10, 
                 episode_length: int = 96,
                 trailing_stop_pct: float = 0.01,
                 trade_ratio: float = 0.5):
        
        super().__init__()
        self.df = df.reset_index(drop=True).copy()
        
        self.window_size = window_size
        self.episode_length = episode_length

        # --- Trading Parameters ---
        self.initial_balance = 300_000.0
        self.min_trade_krw = 5000.0
        self.fee = 0.0005
        self.trade_ratio = trade_ratio
        self.trailing_stop_pct = trailing_stop_pct
        
        # --- Rewards and Penalties ---
        self.reward_scaling = 100.0
        self.profit_bonus = 5.0
        self.loss_penalty = -5.0
        self.shaping_scaling = 1.0 # ë„ˆë¬´ í¬ë‹¤!

        # --- Observation and Action Spaces ---
        
        # Lasso (C=0.01)ë¡œ ì„ íƒëœ 6ê°œì˜ í•µì‹¬ ì§€í‘œ
        self.obs_cols = [
            '30_to_60_Close_ratio', 
            '60_OBV', 
            'day_of_week', 
            '30_ATR', 
            '30_Keltner_lband', 
            '60_ADX'
        ]  
        
        self.portfolio_info_len = 5 
        num_features = len(self.obs_cols) + self.portfolio_info_len
        
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, 
            shape=(self.window_size, num_features), 
            dtype=np.float32
        )
        self.action_space = spaces.Discrete(2)

        # âœ… [ìˆ˜ì •] ì •ê·œí™” í†µê³„ë¥¼ ì™¸ë¶€ì—ì„œ ì£¼ì…ë°›ìŒ
        # (ë°ì´í„° ìœ ì¶œ ë°©ì§€)
        self.obs_means = obs_means
        self.obs_stds = obs_stds
        
        self.highest_price_since_buy = 0.0
        self.reset()

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        
        # 60ë¶„ë´‰ ì§€í‘œ(60_OBV, 60_ADX) ë“±ì„ ìœ„í•œ ì•ˆì „ ë§ˆì§„ (120ì´ë©´ ì¶©ë¶„)
        safe_start_margin = self.window_size + 120 
        
        # âœ… [ìˆ˜ì •] max_start ê³„ì‚° ì‹œ window_sizeë§Œ ë¹¼ë„ ë˜ì§€ë§Œ, 
        #           ì§€í‘œ ê³„ì‚° ë§ˆì§„ì„ ê³ ë ¤í•´ safe_start_marginì„ ì‚¬ìš©
        max_start = len(self.df) - self.episode_length - safe_start_margin
        
        self.start_idx = np.random.randint(0, max_start + 1) if max_start > 0 else 0
        self.current_step = self.start_idx + safe_start_margin
        
        self.step_idx = 0
        self.balance = float(self.initial_balance)
        self.coin_holdings = 0.0
        self.avg_buy_price = 0.0
        self.highest_price_since_buy = 0.0

        self.previous_price = self.df.loc[self.current_step, 'Close']
        
        return self._get_obs(), {}

    def _get_obs(self):
        start = self.current_step - self.window_size + 1
        end = self.current_step + 1
        
        # âš ï¸ window_dfê°€ ë¹„ì–´ìˆëŠ” ê·¹ë‹¨ì ì¸ ê²½ìš° ë°©ì§€
        if start < 0:
            start = 0
            # obs_arrayê°€ (window_size, num_features)ê°€ ì•„ë‹ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê²½ê³ 
            # í•˜ì§€ë§Œ reset() ë¡œì§ìƒ ì´ ê²½ìš°ëŠ” ê±°ì˜ ë°œìƒí•˜ì§€ ì•ŠìŒ
            
        window_df = self.df.iloc[start:end]
        
        # âœ… [ìˆ˜ì •] ì •ê·œí™” ì‹œ (ë¯¸ë˜ ë°ì´í„°ê°€ ì•„ë‹Œ) ì£¼ì…ë°›ì€ í†µê³„(self.obs_means) ì‚¬ìš©
        norm_obs_window = (window_df[self.obs_cols] - self.obs_means) / self.obs_stds
        
        current_price = self.df.loc[self.current_step, 'Close']
        is_holding = 1.0 if self.coin_holdings > 0 else 0.0
        unrealized_pnl = (current_price - self.avg_buy_price) / (self.avg_buy_price + 1e-9) if is_holding else 0.0
        
        portfolio_info = np.array([
            (self.balance - self.initial_balance) / (self.initial_balance * 0.5),
            (self.coin_holdings * current_price) / self.initial_balance,
            is_holding, 
            unrealized_pnl, 
            self.step_idx / max(1, self.episode_length)
        ])
        
        portfolio_info_tiled = np.tile(portfolio_info, (self.window_size, 1))
        
        # âœ… [ìˆ˜ì •] window_dfê°€ window_sizeë³´ë‹¤ ì‘ì„ ê²½ìš° íŒ¨ë”© ì²˜ë¦¬ (ì—í”¼ì†Œë“œ ê·¹ì´ˆë°˜)
        current_window_len = len(norm_obs_window)
        if current_window_len < self.window_size:
            padding = np.zeros((self.window_size - current_window_len, len(self.obs_cols)))
            norm_obs_window_values = np.concatenate([padding, norm_obs_window.values], axis=0)
        else:
            norm_obs_window_values = norm_obs_window.values

        obs_array = np.concatenate([norm_obs_window_values, portfolio_info_tiled], axis=1)
        return obs_array.astype(np.float32)

    # ... ( _calculate_reward, step, _buy, _sell, render ë©”ì„œë“œëŠ” ë™ì¼í•˜ë¯€ë¡œ ìƒëµ )...
    
    def _calculate_reward(self, realized_pnl, is_stop_loss, is_take_profit):
        reward = 0.0
        if realized_pnl != 0:
            reward += realized_pnl * self.reward_scaling
            if is_take_profit:
                reward += self.profit_bonus
            elif is_stop_loss:
                reward += self.loss_penalty
        return float(np.clip(reward, -20.0, 20.0))

    def step(self, action):
        current_price = self.df.loc[self.current_step, 'Close']
        is_holding = self.coin_holdings > 0
        is_stop_loss, is_take_profit, traded = False, False, False
        realized_pnl = 0.0
        
        # âœ… --- [ì¶”ê°€] ë³´ìƒ ì‰ì´í•‘ (Dense Reward) ---
        shaping_reward = 0.0

        # 1. ê°€ê²© ë³€ë™ë¥  ê³„ì‚° (1ìŠ¤í… ì „ ëŒ€ë¹„)
        # (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
        price_change_pct = (current_price - self.previous_price) / (self.previous_price + 1e-9)

        if is_holding:
            # 1. (í™€ë”© ì¤‘) ê°€ê²©ì´ ì˜¤ë¥´ë©´ ë³´ìƒ, ë‚´ë¦¬ë©´ í˜ë„í‹°
            # (ë¯¸ì‹¤í˜„ ì†ìµì˜ 'ë³€í™”ëŸ‰'ì„ ë³´ìƒìœ¼ë¡œ ì¤Œ)
            shaping_reward = price_change_pct
        else:
            # 2. (ë¯¸ë³´ìœ  ì¤‘) ê°€ê²©ì´ ì˜¤ë¥´ë©´ í˜ë„í‹°(ê¸°íšŒë¹„ìš©), ë‚´ë¦¬ë©´ ë³´ìƒ(ì†ì‹¤ íšŒí”¼)
            # (ë§ì”€í•˜ì‹  "ê°€ì§€ê³  ìˆì§€ ì•Šì€ ë™ì•ˆ ì˜¤ë¥´ë©´ í˜ë„í‹°")
            shaping_reward = -price_change_pct

        # ì‰ì´í•‘ ë³´ìƒì— ê°€ì¤‘ì¹˜ ì ìš©
        shaping_reward *= self.shaping_scaling
        # -----------------------------------------------

        # 1. ìë™ ë§¤ë„ ë¡œì§ (íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘)
        if is_holding:
            self.highest_price_since_buy = max(self.highest_price_since_buy, current_price)
            trailing_stop_price = self.highest_price_since_buy * (1 - self.trailing_stop_pct)
            
            if current_price <= trailing_stop_price:
                _, r_pnl = self._sell(self.coin_holdings, current_price)
                realized_pnl += r_pnl
                traded = True
                
                if realized_pnl > 0:
                    is_take_profit = True
                else:
                    is_stop_loss = True

        # 2. ì—ì´ì „íŠ¸ì˜ ë§¤ìˆ˜ ë¡œì§
        elif not is_holding and action == 1:
            cost_to_spend = self.balance * self.trade_ratio
            buy_qty = cost_to_spend / current_price if current_price > 0 else 0
            cost = self._buy(buy_qty, current_price)
            if cost > 0:
                traded = True

        # --- Calculate reward and move to the next step ---
        # âœ… [ìˆ˜ì •] ìµœì¢… ìŠ¤í… ë³´ìƒ = (ë§¤ë„ ë³´ìƒ) + (ì‰ì´í•‘ ë³´ìƒ)
        realized_reward = self._calculate_reward(realized_pnl, is_stop_loss, is_take_profit)
        step_reward = realized_reward + shaping_reward # ğŸ‘ˆ ë‘ ë³´ìƒì„ í•©ì‚°

        # âœ… [ì¶”ê°€] ë‹¤ìŒ ìŠ¤í…ì„ ìœ„í•´ í˜„ì¬ ê°€ê²©ì„ 'ì´ì „ ê°€ê²©'ìœ¼ë¡œ ì €ì¥
        self.previous_price = current_price
        
        self.current_step += 1
        self.step_idx += 1
        
        # âœ… [ìˆ˜ì •] ì¢…ë£Œ ì¡°ê±´ ê°•í™”: ë°ì´í„° ëì— ë„ë‹¬í•˜ê¸° ìµœì†Œ 1ìŠ¤í… ì „ì— ì¢…ë£Œ
        terminated = self.current_step >= (len(self.df) - 1)
        truncated = self.step_idx >= self.episode_length
        
        # ì¢…ë£Œ/ì¤‘ë‹¨ ì‹œ obsë¥¼ ê°€ì ¸ì˜¤ì§€ ì•Šê³  ë¹ˆ dictì™€ í•¨ê»˜ ë¦¬ì…‹ obs ë°˜í™˜ ì¤€ë¹„
        if terminated or truncated:
            obs = self._get_obs() # ë§ˆì§€ë§‰ obsë¥¼ ê°€ì ¸ì˜¤ê¸´ í•˜ì§€ë§Œ...
            info = {'asset': self.balance + self.coin_holdings * current_price}
            # ... ë‹¤ìŒ reset()ì—ì„œ ìƒˆ obsê°€ ë‚˜ê°ˆ ê²ƒì„
        else:
            obs = self._get_obs()
            info = {'asset': self.balance + self.coin_holdings * current_price}
            
        return obs, step_reward, terminated, truncated, info

    def _buy(self, qty, price):
        if qty <= 0 or price <= 0: return 0.0
        cost = qty * price * (1 + self.fee)
        if cost < self.min_trade_krw or cost > self.balance: return 0.0
        
        self.avg_buy_price = price
        self.coin_holdings = qty
        self.balance -= cost
        self.highest_price_since_buy = price
        return cost

    def _sell(self, qty, price):
        if qty <= 0 or price <= 0 or self.coin_holdings <= 0: return 0.0, 0.0
        
        revenue = qty * price * (1 - self.fee)
        realized_pnl = (price - self.avg_buy_price) / (self.avg_buy_price + 1e-9)
        
        self.coin_holdings = 0.0
        self.avg_buy_price = 0.0
        self.balance += revenue
        self.highest_price_since_buy = 0.0
        return revenue, realized_pnl

    def render(self, mode="human"):
        current_price = self.df.loc[self.current_step, 'Close']
        total_asset = self.balance + self.coin_holdings * current_price
        
        is_holding = self.coin_holdings > 0
        trailing_stop_price = self.highest_price_since_buy * (1 - self.trailing_stop_pct) if is_holding else 0
        
        print(f"[Step {self.step_idx:03d}] Asset: {total_asset:,.0f} | "
              f"Holdings: {self.coin_holdings:.4f} | "
              f"Balance: {self.balance:,.0f} | "
              f"Current Stop: {trailing_stop_price:,.0f}")