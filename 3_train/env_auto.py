import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pandas as pd

class TradingEnv(gym.Env):
    """
    [ìˆ˜ì •ë¨]
    - ì •ê·œí™” í†µê³„(means/stds)ë¥¼ ì™¸ë¶€ì—ì„œ ì£¼ì…ë°›ìŒ (Lookahead Bias ë°©ì§€).
    - í–‰ë™ ê³µê°„ì„ 3ê°œ(ë¯¸ë³´ìœ , ë§¤ìˆ˜, ë§¤ë„)ë¡œ í™•ì¥í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ ë§¤ë„ íƒ€ì´ë°ì„ í•™ìŠµí•˜ë„ë¡ í•¨.
    - íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ìë™ ë§¤ë„ ë¡œì§ ì œê±°.
    """
    metadata = {"render.modes": ["human"]}

    def __init__(self, df: pd.DataFrame, 
                 obs_means: pd.Series, 
                 obs_stds: pd.Series,
                 window_size: int = 10, 
                 episode_length: int = 96,
                 trade_ratio: float = 0.5):
        
        super().__init__()
        self.df = df.reset_index(drop=True).copy()
        
        self.window_size = window_size
        self.episode_length = episode_length

        # --- Trading Parameters ---
        self.initial_balance = 300_000.0
        self.min_trade_krw = 5000.0
        self.fee = 0.0005
        self.trade_ratio = trade_ratio
        
        # --- Rewards and Penalties ---
        self.reward_scaling = 100.0
        self.profit_bonus = 5.0
        self.loss_penalty = -5.0
        self.shaping_scaling = 50.0

        # --- Observation and Action Spaces ---
        
        self.obs_cols = ['60_BB_Width', 
                         '30_VPT', 
                         '30_ADI', 
                         'day_of_week', 
                         '30_OBV', 
                         '30_to_60_Close_ratio', 
                         '30_BB_High', 
                         '30_ATR', 
                         '60_ADX']
        
        self.portfolio_info_len = 5 
        num_features = len(self.obs_cols) + self.portfolio_info_len
        
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, 
            shape=(self.window_size, num_features), 
            dtype=np.float32
        )
        # âœ… [ìˆ˜ì •] í–‰ë™ ê³µê°„ í™•ì¥: 0:ìœ ì§€(or ë¯¸ë³´ìœ  ìœ ì§€), 1:ë§¤ìˆ˜, 2:ë§¤ë„
        self.action_space = spaces.Discrete(3) 

        # âœ… [ìˆ˜ì •] ì •ê·œí™” í†µê³„ë¥¼ ì™¸ë¶€ì—ì„œ ì£¼ì…ë°›ìŒ
        self.obs_means = obs_means
        self.obs_stds = obs_stds
        
        self.reset()

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        
        safe_start_margin = self.window_size + 120 
        max_start = len(self.df) - self.episode_length - safe_start_margin
        
        self.start_idx = np.random.randint(0, max_start + 1) if max_start > 0 else 0
        self.current_step = self.start_idx + safe_start_margin
        
        self.step_idx = 0
        self.balance = float(self.initial_balance)
        self.coin_holdings = 0.0
        self.avg_buy_price = 0.0
        self.steps_since_buy = 0 # â­ï¸ [ì¶”ê°€] ë³´ìœ  ê¸°ê°„ ì¹´ìš´í„° ì´ˆê¸°í™”

        self.previous_price = self.df.loc[self.current_step, 'Close']
        
        return self._get_obs(), {}
    
    def _get_obs(self):
        start = self.current_step - self.window_size + 1
        end = self.current_step + 1
        
        if start < 0:
            start = 0
            
        window_df = self.df.iloc[start:end]
        
        # ì •ê·œí™” ì‹œ ì£¼ì…ë°›ì€ í†µê³„(self.obs_means) ì‚¬ìš©
        norm_obs_window = (window_df[self.obs_cols] - self.obs_means) / self.obs_stds
        
        current_price = self.df.loc[self.current_step, 'Close']
        is_holding = 1.0 if self.coin_holdings > 0 else 0.0
        unrealized_pnl = (current_price - self.avg_buy_price) / (self.avg_buy_price + 1e-9) if is_holding else 0.0
        
        # â­ï¸â­ï¸â­ï¸ [í•µì‹¬ ìˆ˜ì •] â­ï¸â­ï¸â­ï¸
        # ì—í”¼ì†Œë“œ ì§„í–‰ë¥  ëŒ€ì‹  'ë³´ìœ  ì‹œê°„ ì§„í–‰ë¥ 'ì„ ê´€ì¸¡ì¹˜ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        MAX_HOLD_STEPS = 48.0 # 24ì‹œê°„ (48 ìŠ¤í…)
        holding_time_ratio = (self.steps_since_buy / MAX_HOLD_STEPS) if is_holding else 0.0
        # â­ï¸â­ï¸â­ï¸ [ìˆ˜ì • ë] â­ï¸â­ï¸â­ï¸

        portfolio_info = np.array([
            (self.balance - self.initial_balance) / (self.initial_balance * 0.5),
            (self.coin_holdings * current_price) / self.initial_balance,
            is_holding, 
            unrealized_pnl, 
            holding_time_ratio
        ])
        
        portfolio_info_tiled = np.tile(portfolio_info, (self.window_size, 1))
        
        current_window_len = len(norm_obs_window)
        if current_window_len < self.window_size:
            padding = np.zeros((self.window_size - current_window_len, len(self.obs_cols)))
            norm_obs_window_values = np.concatenate([padding, norm_obs_window.values], axis=0)
        else:
            norm_obs_window_values = norm_obs_window.values

        obs_array = np.concatenate([norm_obs_window_values, portfolio_info_tiled], axis=1)
        return obs_array.astype(np.float32)

    def _calculate_reward(self, realized_pnl, is_stop_loss, is_take_profit):
        reward = 0.0
        if realized_pnl != 0:
            reward += realized_pnl * self.reward_scaling
            if is_take_profit:
                reward += self.profit_bonus
            elif is_stop_loss:
                reward += self.loss_penalty
        return float(np.clip(reward, -20.0, 20.0))

    def step(self, action):
        current_price = self.df.loc[self.current_step, 'Close']
        is_holding = self.coin_holdings > 0
        is_stop_loss, is_take_profit, traded = False, False, False
        realized_pnl = 0.0

        # â­ï¸â­ï¸â­ï¸ [1. ë³´ìœ  ê¸°ê°„(24ì‹œê°„) ê°•ì œ ì²­ì‚° ë¡œì§] â­ï¸â­ï¸â­ï¸
        MAX_HOLD_STEPS = 48 # 24ì‹œê°„ = 48 ìŠ¤í… (30ë¶„ë´‰ ê¸°ì¤€)
        shaping_reward = 0.0

        if is_holding:
            self.steps_since_buy += 1 # ë³´ìœ  ê¸°ê°„ 1 ìŠ¤í… ì¦ê°€
            
            if self.steps_since_buy >= MAX_HOLD_STEPS:
                # 24ì‹œê°„ì´ ì§€ë‚˜ë©´ ê°•ì œ ë§¤ë„ ì‹¤í–‰
                _, r_pnl = self._sell(self.coin_holdings, current_price)
                realized_pnl = r_pnl # ì‹¤í˜„ ì†ìµ(PnL) ê¸°ë¡
                traded = True
                
                # â­ï¸ ê°•ì œ ì²­ì‚° ê²°ê³¼ë¥¼ ë³´ìƒ í•¨ìˆ˜ì— ë°˜ì˜í•˜ê¸° ìœ„í•´ í”Œë˜ê·¸ ì„¤ì •
                if realized_pnl > 0:
                    is_take_profit = True
                else:
                    is_stop_loss = True # ì‹œê°„ ì¢…ë£Œë¡œ ì¸í•œ ì²­ì‚° (ì†ì‹¤/ë³¸ì „)
                
                # â­ï¸ ê°•ì œ ì²­ì‚°ì´ ë°œìƒí–ˆìœ¼ë¯€ë¡œ, ì—ì´ì „íŠ¸ì˜ í˜„ì¬ actionì„ ë¬´ì‹œ (0:ìœ ì§€)
                action = 0 
                shaping_reward -= 10.0
        # â­ï¸â­ï¸â­ï¸ [ë¡œì§ ì¶”ê°€ ë] â­ï¸â­ï¸â­ï¸

        # --- 2. ë³´ìƒ ì‰ì´í•‘ (Dense Reward) ---
        price_change_pct = (current_price - self.previous_price) / (self.previous_price + 1e-9)

        if is_holding:
            # (í™€ë”© ì¤‘) ê°€ê²© ë³€ë™ì— ë”°ë¥¸ ë¯¸ì‹¤í˜„ ì†ìµ ë³€í™”ëŸ‰ ì‰ì´í•‘
            shaping_reward = price_change_pct
        else:
            # (ë¯¸ë³´ìœ  ì¤‘) ê°€ê²© ë³€ë™ì— ë”°ë¥¸ ê¸°íšŒë¹„ìš©/ì†ì‹¤ íšŒí”¼ ì‰ì´í•‘
            shaping_reward = -price_change_pct
        
        if action == 1 and is_holding: 
            shaping_reward += -0.1 
        elif action == 2 and not is_holding: 
            shaping_reward += -0.1

        shaping_reward *= self.shaping_scaling
        # -----------------------------------------------

        # --- 3. ì—ì´ì „íŠ¸ í–‰ë™ ë¡œì§ (ê°•ì œ ì²­ì‚°ì´ ì•„ë‹ ê²½ìš°) ---

        # 1. ì—ì´ì „íŠ¸ì˜ ë§¤ìˆ˜ ë¡œì§ (Action == 1)
        if action == 1 and not is_holding:
            cost_to_spend = self.balance * self.trade_ratio
            buy_qty = cost_to_spend / current_price if current_price > 0 else 0
            cost = self._buy(buy_qty, current_price)
            if cost > 0:
                traded = True

        # 2. ì—ì´ì „íŠ¸ì˜ ë§¤ë„ ë¡œì§ (Action == 2)
        elif action == 2 and is_holding:
            _, r_pnl = self._sell(self.coin_holdings, current_price)
            realized_pnl += r_pnl
            traded = True
            
            if realized_pnl > 0:
                is_take_profit = True
                shaping_reward += 5.0 
            else:
                is_stop_loss = True
                shaping_reward += -2.0 

        # --- 4. Calculate reward and move to the next step ---
        # â­ï¸ (ê°•ì œ ì²­ì‚° ë˜ëŠ” ì—ì´ì „íŠ¸ ë§¤ë„ë¡œ ë°œìƒí•œ) ì‹¤í˜„ ì†ìµì„ ë³´ìƒ í•¨ìˆ˜ì— ì „ë‹¬
        realized_reward = self._calculate_reward(realized_pnl, is_stop_loss, is_take_profit)
        step_reward = realized_reward + shaping_reward 

        self.previous_price = current_price
        
        self.current_step += 1
        self.step_idx += 1
        
        terminated = self.current_step >= (len(self.df) - 1)
        truncated = self.step_idx >= self.episode_length
        
        # ì¢…ë£Œ/ì¤‘ë‹¨ ì²˜ë¦¬
        if terminated or truncated:
            if self.coin_holdings > 0:
                _, end_pnl = self._sell(self.coin_holdings, current_price)
                # (ì„ íƒ) ë§ˆì§€ë§‰ ì²­ì‚° PnLë„ ë³´ìƒì— ì¶”ê°€
                # step_reward += self._calculate_reward(end_pnl, end_pnl < 0, end_pnl > 0) 
            
            obs = self._get_obs() 
            current_asset = self.balance + self.coin_holdings * current_price
            info = {'asset': current_asset}

        else:
            obs = self._get_obs()
            current_asset = self.balance + self.coin_holdings * current_price
            info = {'asset': current_asset}
            
        return obs, step_reward, terminated, truncated, info

    def _buy(self, qty, price):
        if qty <= 0 or price <= 0: return 0.0
        cost = qty * price * (1 + self.fee)
        # ìµœì†Œ ê±°ë˜ ê¸ˆì•¡ ë° ì”ê³  í™•ì¸
        if cost < self.min_trade_krw or cost > self.balance: return 0.0
        
        # ê¸°ì¡´ ë³´ìœ  ì½”ì¸ ì—†ì´ ìƒˆë¡œ ë§¤ìˆ˜í•˜ë¯€ë¡œ, ë‹¨ìˆœ ì„¤ì •
        self.avg_buy_price = price
        self.coin_holdings = qty
        self.balance -= cost
        self.steps_since_buy = 0 # â­ï¸ [ì¶”ê°€] ë§¤ìˆ˜ ì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
        return cost
        if qty <= 0 or price <= 0: return 0.0
        cost = qty * price * (1 + self.fee)
        # ìµœì†Œ ê±°ë˜ ê¸ˆì•¡ ë° ì”ê³  í™•ì¸
        if cost < self.min_trade_krw or cost > self.balance: return 0.0
        
        # ê¸°ì¡´ ë³´ìœ  ì½”ì¸ ì—†ì´ ìƒˆë¡œ ë§¤ìˆ˜í•˜ë¯€ë¡œ, ë‹¨ìˆœ ì„¤ì •
        self.avg_buy_price = price
        self.coin_holdings = qty
        self.balance -= cost
        return cost

    def _sell(self, qty, price):
        if qty <= 0 or price <= 0 or self.coin_holdings <= 0: return 0.0, 0.0
        
        revenue = qty * price * (1 - self.fee)
        realized_pnl = (price - self.avg_buy_price) / (self.avg_buy_price + 1e-9)
        
        # âœ… [ìˆ˜ì •] ë§¤ë„ í›„ í¬íŠ¸í´ë¦¬ì˜¤ ì´ˆê¸°í™”
        self.coin_holdings = 0.0
        self.avg_buy_price = 0.0
        self.balance += revenue
        self.steps_since_buy = 0 # â­ï¸ [ì¶”ê°€] ë§¤ë„ ì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
        return revenue, realized_pnl
        if qty <= 0 or price <= 0 or self.coin_holdings <= 0: return 0.0, 0.0
        
        revenue = qty * price * (1 - self.fee)
        realized_pnl = (price - self.avg_buy_price) / (self.avg_buy_price + 1e-9)
        
        # âœ… [ìˆ˜ì •] ë§¤ë„ í›„ í¬íŠ¸í´ë¦¬ì˜¤ ì´ˆê¸°í™”
        self.coin_holdings = 0.0
        self.avg_buy_price = 0.0
        self.balance += revenue
        return revenue, realized_pnl

    def render(self, mode="human"):
        current_price = self.df.loc[self.current_step, 'Close']
        total_asset = self.balance + self.coin_holdings * current_price
        
        is_holding = self.coin_holdings > 0
        
        print(f"ğŸ“ˆ [Step {self.step_idx:03d}] Asset: {total_asset:,.0f} | "
              f"Holdings: {self.coin_holdings:.4f} | "
              f"Balance: {self.balance:,.0f} | "
              f"Holding: {'O' if is_holding else 'X'}")