import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pandas as pd
import random
from typing import Optional, Tuple, Any

class TradingEnv(gym.Env):
    """
    [í›ˆë ¨ìš© í™˜ê²½ - env2.py ê¸°ë°˜ ìˆ˜ì •ë¨]
    - SB3 RecurrentPPO í•™ìŠµì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì„¤ê³„
    - ì •ê·œí™” í†µê³„(means/stds)ë¥¼ ì™¸ë¶€ì—ì„œ ì£¼ì…ë°›ìŒ.
    - í–‰ë™ ê³µê°„: 0:ìœ ì§€/ë¯¸ë³´ìœ , 1:ë§¤ìˆ˜, 2:ë§¤ë„
    - âœ… 24ì‹œê°„(48 ìŠ¤í…) ê°•ì œ ì²­ì‚° ë¡œì§ ë° ë³´ìœ  ê¸°ê°„ ê´€ì¸¡ì¹˜ ì¶”ê°€
    """
    metadata = {"render_modes": ["human"]} 
    
    # â­ï¸ [ì¶”ê°€] ìµœëŒ€ ë³´ìœ  ê¸°ê°„ ìƒìˆ˜
    MAX_HOLD_STEPS = 48 # 24ì‹œê°„ = 48 ìŠ¤í… (30ë¶„ë´‰ ê¸°ì¤€)

    def __init__(self, df: pd.DataFrame, 
                 obs_means: pd.Series, 
                 obs_stds: pd.Series,
                 window_size: int = 10, 
                 episode_length: int = 96,
                 trade_ratio: float = 0.5):
        
        super().__init__()
        self.df = df.copy() 
        self.window_size = window_size
        self.episode_length = episode_length
        self.random_start_margin = 120 

        # --- Trading Parameters ---
        self.initial_balance = 300_000.0
        self.min_trade_krw = 5000.0
        self.fee = 0.0005
        self.trade_ratio = trade_ratio
        
        # --- Rewards and Penalties ---
        self.reward_scaling = 100.0
        self.profit_bonus = 5.0
        self.loss_penalty = -5.0
        self.shaping_scaling = 50.0

        # --- Observation and Action Spaces ---
        self.obs_cols = ['60_BB_Width', '30_VPT', '30_ADI', 'day_of_week', '30_OBV', 
                         '30_to_60_Close_ratio', '30_BB_High', '30_ATR', '60_ADX']
        
        self.portfolio_info_len = 5 
        num_features = len(self.obs_cols) + self.portfolio_info_len
        
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, 
            shape=(self.window_size, num_features), 
            dtype=np.float32
        )
        self.action_space = spaces.Discrete(3) 

        self.obs_means = obs_means
        self.obs_stds = obs_stds
        
        self.df_index = self.df.index 
        
        self.max_episode_start_idx = len(self.df) - self.episode_length - self.window_size - self.random_start_margin

    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None) -> Tuple[np.ndarray, dict]:
        super().reset(seed=seed)
        
        if self.max_episode_start_idx < 0:
             self.start_idx = 0 
        else:
             self.start_idx = self.np_random.integers(0, self.max_episode_start_idx + 1)
        
        self.current_step_df_idx = self.start_idx + self.window_size + self.random_start_margin
        
        self.step_idx = 0
        self.balance = float(self.initial_balance)
        self.coin_holdings = 0.0
        self.avg_buy_price = 0.0
        self.steps_since_buy = 0 # â­ï¸ [ì¶”ê°€] ë³´ìœ  ê¸°ê°„ ì¹´ìš´í„° ì´ˆê¸°í™”

        self.previous_price = self.df.iloc[self.current_step_df_idx]['Close']
        
        info = self._get_info()
        return self._get_obs(), info

    def _get_obs(self) -> np.ndarray:
        end_iloc = self.current_step_df_idx + 1
        start_iloc = end_iloc - self.window_size
        
        if start_iloc < 0:
             start_iloc = 0
             
        window_df = self.df.iloc[start_iloc:end_iloc]
        
        norm_obs_window = (window_df[self.obs_cols] - self.obs_means) / self.obs_stds
        
        current_price = self.df.iloc[self.current_step_df_idx]['Close']
        is_holding = 1.0 if self.coin_holdings > 0 else 0.0
        unrealized_pnl = (current_price - self.avg_buy_price) / (self.avg_buy_price + 1e-9) if is_holding else 0.0
        
        # â­ï¸ [ìˆ˜ì •] ì—í”¼ì†Œë“œ ì§„í–‰ë¥  ëŒ€ì‹  'ë³´ìœ  ì‹œê°„ ì§„í–‰ë¥ 'ì„ ê´€ì¸¡ì¹˜ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        holding_time_ratio = (self.steps_since_buy / self.MAX_HOLD_STEPS) if is_holding else 0.0

        portfolio_info = np.array([
            (self.balance - self.initial_balance) / (self.initial_balance * 0.5), 
            (self.coin_holdings * current_price) / self.initial_balance,           
            is_holding, 
            unrealized_pnl, 
            holding_time_ratio # âœ… ë³´ìœ  ì‹œê°„ ë¹„ìœ¨
        ])
        
        portfolio_info_tiled = np.tile(portfolio_info, (self.window_size, 1))
        
        current_window_len = len(norm_obs_window)
        if current_window_len < self.window_size:
            padding = np.zeros((self.window_size - current_window_len, len(self.obs_cols)))
            norm_obs_window_values = np.concatenate([padding, norm_obs_window.values], axis=0)
        else:
            norm_obs_window_values = norm_obs_window.values

        obs_array = np.concatenate([norm_obs_window_values, portfolio_info_tiled], axis=1)
        return obs_array.astype(np.float32)

    def _get_info(self) -> dict:
        current_price = self.df.iloc[self.current_step_df_idx]['Close']
        total_asset = self.balance + self.coin_holdings * current_price
        
        info = {
            'date': self.df.index[self.current_step_df_idx],
            'current_value': total_asset, 
            'balance': self.balance,
            'holdings': self.coin_holdings,
            'avg_buy_price': self.avg_buy_price,
            'is_holding': self.coin_holdings > 0,
        }
        return info

    def _calculate_reward(self, realized_pnl: float, is_stop_loss: bool, is_take_profit: bool) -> float:
        reward = 0.0
        if realized_pnl != 0:
            reward += realized_pnl * self.reward_scaling
            if is_take_profit:
                reward += self.profit_bonus
            elif is_stop_loss:
                reward += self.loss_penalty
        return float(np.clip(reward, -20.0, 20.0))

    def step(self, action: Any) -> Tuple[np.ndarray, float, bool, bool, dict]:
        current_price = self.df.iloc[self.current_step_df_idx]['Close']
        is_holding = self.coin_holdings > 0
        is_stop_loss, is_take_profit, traded = False, False, False
        realized_pnl = 0.0 
        
        shaping_reward = 0.0
        
        # â­ï¸â­ï¸â­ï¸ [1. ë³´ìœ  ê¸°ê°„(24ì‹œê°„) ê°•ì œ ì²­ì‚° ë¡œì§] â­ï¸â­ï¸â­ï¸
        if is_holding:
            self.steps_since_buy += 1 # ë³´ìœ  ê¸°ê°„ 1 ìŠ¤í… ì¦ê°€
            
            if self.steps_since_buy >= self.MAX_HOLD_STEPS:
                # 24ì‹œê°„ì´ ì§€ë‚˜ë©´ ê°•ì œ ë§¤ë„ ì‹¤í–‰
                _, r_pnl = self._sell(self.coin_holdings, current_price)
                realized_pnl = r_pnl 
                traded = True
                
                # ê°•ì œ ì²­ì‚° ê²°ê³¼ í”Œë˜ê·¸ ì„¤ì •
                if realized_pnl > 0:
                    is_take_profit = True
                else:
                    is_stop_loss = True
                
                # ê°•ì œ ì²­ì‚°ì´ ë°œìƒí–ˆìœ¼ë¯€ë¡œ, ì—ì´ì „íŠ¸ì˜ í˜„ì¬ actionì„ ë¬´ì‹œ (0:ìœ ì§€)
                action = 0 
                shaping_reward -= 10.0 # ê°•ì œ ì²­ì‚°ì— ëŒ€í•œ í˜ë„í‹°
        # â­ï¸â­ï¸â­ï¸ [ë¡œì§ ì¶”ê°€ ë] â­ï¸â­ï¸â­ï¸

        # --- 2. ë³´ìƒ ì‰ì´í•‘ (Dense Reward) ---
        price_change_pct = (current_price - self.previous_price) / (self.previous_price + 1e-9)

        if is_holding:
            shaping_reward += price_change_pct 
        else:
            shaping_reward += -price_change_pct 
        
        if action == 1 and is_holding: shaping_reward += -0.1 
        elif action == 2 and not is_holding: shaping_reward += -0.1

        shaping_reward *= self.shaping_scaling
        # -----------------------------------------------

        # --- 3. ì—ì´ì „íŠ¸ í–‰ë™ ë¡œì§ (ê°•ì œ ì²­ì‚°ì´ ì•„ë‹ ê²½ìš°) ---

        # 1. ë§¤ìˆ˜ ë¡œì§ (Action == 1)
        if action == 1 and not is_holding:
            cost_to_spend = self.balance * self.trade_ratio
            buy_qty = cost_to_spend / current_price if current_price > 0 else 0
            cost = self._buy(buy_qty, current_price)
            if cost > 0: traded = True

        # 2. ë§¤ë„ ë¡œì§ (Action == 2)
        elif action == 2 and is_holding:
            _, r_pnl = self._sell(self.coin_holdings, current_price)
            realized_pnl += r_pnl
            traded = True
            
            if realized_pnl > 0:
                is_take_profit = True
                shaping_reward += 5.0 
            else:
                is_stop_loss = True
                shaping_reward += -2.0 

        # --- 4. Calculate reward and move to the next step ---
        realized_reward = self._calculate_reward(realized_pnl, is_stop_loss, is_take_profit)
        step_reward = realized_reward + shaping_reward 

        self.previous_price = current_price
        
        self.current_step_df_idx += 1
        self.step_idx += 1
        
        terminated = self.current_step_df_idx >= (len(self.df) - 1)
        truncated = self.step_idx >= self.episode_length
        
        # --- ì •ë³´ ë° ê´€ì¸¡ì¹˜ ë°˜í™˜ ---
        info = self._get_info()
        info['traded'] = traded 

        if terminated or truncated:
            # ì—í”¼ì†Œë“œ ì¢…ë£Œ ì‹œ ê°•ì œ ì²­ì‚° (ì¢…ë£Œ ë³´ìƒ)
            if self.coin_holdings > 0:
                _, end_pnl = self._sell(self.coin_holdings, current_price)
                step_reward += self._calculate_reward(end_pnl, end_pnl < 0, end_pnl > 0)
                
            info = self._get_info() 
        
        obs = self._get_obs() 
        
        return obs, step_reward, terminated, truncated, info

    def _buy(self, qty, price):
        if qty <= 0 or price <= 0: return 0.0
        cost = qty * price * (1 + self.fee)
        if cost < self.min_trade_krw or cost > self.balance: return 0.0
        
        self.avg_buy_price = price
        self.coin_holdings = qty
        self.balance -= cost
        self.steps_since_buy = 0 # â­ï¸ [ì¶”ê°€] ë§¤ìˆ˜ ì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
        return cost

    def _sell(self, qty, price):
        if qty <= 0 or price <= 0 or self.coin_holdings <= 0: return 0.0, 0.0
        
        revenue = qty * price * (1 - self.fee)
        realized_pnl = (price - self.avg_buy_price) / (self.avg_buy_price + 1e-9)
        
        self.coin_holdings = 0.0
        self.avg_buy_price = 0.0
        self.balance += revenue
        self.steps_since_buy = 0 # â­ï¸ [ì¶”ê°€] ë§¤ë„ ì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
        return revenue, realized_pnl

    def render(self, mode="human"):
        current_price = self.df.iloc[self.current_step_df_idx]['Close']
        total_asset = self.balance + self.coin_holdings * current_price
        is_holding = self.coin_holdings > 0
        
        print(f"ğŸ“ˆ [Step {self.step_idx:03d}] Asset: {total_asset:,.0f} | "
              f"Holdings: {self.coin_holdings:.4f} | "
              f"Balance: {self.balance:,.0f} | "
              f"Holding: {'O' if is_holding else 'X'}")

    def close(self):
        pass